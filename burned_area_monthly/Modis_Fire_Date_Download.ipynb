{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListofExtensionAndName(directory,extension):\n",
    "     \n",
    "        if len(directory) != None:\n",
    "            import os\n",
    "            FilesList = []\n",
    "            FileName=[]\n",
    "            for root, subdirectory, files in os.walk(directory):\n",
    "                for file in files:\n",
    "                    if file.endswith(extension):\n",
    "                        FilesList.append(os.path.join(root,file))\n",
    "                        base=os.path.basename(file)\n",
    "                        FileName.append(os.path.splitext(base)[0])\n",
    "\n",
    "            return sorted(FilesList),sorted(FileName)\n",
    "        else:\n",
    "            print(\"no\"+ extension +\"file for this directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import earth data username and password from config.py file which is in the same folder with this jupyter notebook\n",
    "import config\n",
    "username=config.username\n",
    "password=config.password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from osgeo import gdal,osr\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main url of fire date data folder\n",
    "url='https://e4ftl01.cr.usgs.gov/MOTA/MCD64A1.006/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_page=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list=modis_page.find_all('a')[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create yearly and monthly folder\n",
    "for year in year_list[49:61]:\n",
    "    year_info=int(str(year['href']).split('.')[0])\n",
    "    year_path=main_folder+str(year_info)\n",
    "    try:\n",
    "        os.mkdir(year_path)       \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        folder_path=str(year_path)+'/'+str(year['href'])\n",
    "        print(folder_path)\n",
    "        os.mkdir(folder_path)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.cookiejar as CookieJar\n",
    "from urllib.parse import urlencode \n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download folder of data which are save by monthly under this folder\n",
    "main_folder='../data/Modis_Fire_Date/'\n",
    "# starting index 1 because we want to start 2001.01 data\n",
    "\n",
    "for year in year_list[52:61]:\n",
    "    # In this script, year means month of the year. ex: <a href=\"2001.01.01/\">2001.01.01/</a>\n",
    "    \n",
    "    # main url of fire date data folder\n",
    "    url='https://e4ftl01.cr.usgs.gov/MOTA/MCD64A1.006/'\n",
    "    url_year=url+str(year['href'])\n",
    "    year_info=int(str(year['href']).split('.')[0])\n",
    "    print(url_year)\n",
    "    \n",
    "    #if you want to download spesific year you can define year. if you want to give range between years>>\n",
    "    # >  if year_info>2004 and year_info<2010  \n",
    "    #if year_info<2018:\n",
    "        #print(year_info)\n",
    "        #continue\n",
    "    \n",
    "    page=requests.get(url_year)\n",
    "    year_page=BeautifulSoup(page.content,'html.parser')\n",
    "    links = year_page.findAll(href=re.compile(\"\\.hdf$\"))\n",
    "    \n",
    "    # check the dwonload path.\n",
    "    # sample >>>  data/Modis_Fire_Date/2001/2001.01.01\n",
    "    download_path=main_folder+str(year_info)+'/'+str(year['href'])\n",
    "    \n",
    "    for l in links:\n",
    "        \n",
    "        image_bool=False\n",
    "        #with these block, we are run same url until it's finished\n",
    "        while image_bool is False:\n",
    "            try:\n",
    "                url_img=url_year+l['href']\n",
    "                image_path=download_path+l['href']\n",
    "                if os.path.exists(image_path):\n",
    "                    #if this file already exist in target file, skip it\n",
    "                    image_bool=True\n",
    "                    continue\n",
    "                \n",
    "                username = username\n",
    "                password = password\n",
    "                password_manager = urllib2.HTTPPasswordMgrWithDefaultRealm()\n",
    "                password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    "                cookie_jar = CookieJar.CookieJar()\n",
    "                opener = urllib2.build_opener(urllib2.HTTPBasicAuthHandler(password_manager),\n",
    "                                              #urllib2.HTTPHandler(debuglevel=1),    # Uncomment these two lines to see\n",
    "                                              #urllib2.HTTPSHandler(debuglevel=1),   # details of the requests/responses\n",
    "                                              urllib2.HTTPCookieProcessor(cookie_jar))\n",
    "                urllib2.install_opener(opener)\n",
    "                request = urllib2.Request(url_img)\n",
    "                response = urllib2.urlopen(request)\n",
    "                 \n",
    "                with open(image_path, 'wb') as f:\n",
    "                    f.write(response.read())\n",
    "                    image_bool=True\n",
    "                    #print(image_path)\n",
    "                    time.sleep(1)\n",
    "            except:\n",
    "                time.sleep(60)\n",
    "                print (\"Unexpected error:\", sys.exc_info()[0])\n",
    "                image_bool=False\n",
    "                pass\n",
    "    # script waits 2 minutes when a year is finished      \n",
    "    time.sleep(120)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
